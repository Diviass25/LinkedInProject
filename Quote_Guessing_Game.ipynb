{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bee4333b"
      },
      "source": [
        "## Refactor Scraping Logic\n",
        "\n",
        "Encapsulate the web scraping part into a dedicated function `scrape_all_quotes` that returns the list of quotes.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "72283b1d",
        "outputId": "ad65e489-d77a-4029-8711-b44993c2df24"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from csv import writer\n",
        "from time import sleep\n",
        "from random import choice\n",
        "\n",
        "def scrape_all_quotes():\n",
        "    # list to store scraped data\n",
        "    all_quotes = []\n",
        "\n",
        "    # this part of the url is constant\n",
        "    base_url = \"http://quotes.toscrape.com/\"\n",
        "\n",
        "    # this part of the url will keep changing\n",
        "    url = \"/page/1\"\n",
        "\n",
        "    while url:\n",
        "        # concatenating both urls\n",
        "        # making request\n",
        "        res = requests.get(f\"{base_url}{url}\")\n",
        "        print(f\"Now Scraping {base_url}{url}\")\n",
        "        soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "        # extracting all elements\n",
        "        quotes = soup.find_all(class_=\"quote\")\n",
        "\n",
        "        for quote in quotes:\n",
        "            all_quotes.append({\n",
        "                \"text\": quote.find(class_=\"text\").get_text(),\n",
        "                \"author\": quote.find(class_=\"author\").get_text(),\n",
        "                \"bio-link\": quote.find(\"a\")[\"href\"]\n",
        "            })\n",
        "        next_btn = soup.find(class_=\"next\")\n",
        "        url = next_btn.find(\"a\")[\"href\"] if next_btn else None\n",
        "        sleep(2)\n",
        "    return all_quotes\n",
        "\n",
        "# Call the function to scrape all quotes\n",
        "all_quotes_data = scrape_all_quotes()\n",
        "\n",
        "# The game-related code is removed as per the instructions.\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Scraping http://quotes.toscrape.com//page/1\n",
            "Now Scraping http://quotes.toscrape.com//page/2/\n",
            "Now Scraping http://quotes.toscrape.com//page/3/\n",
            "Now Scraping http://quotes.toscrape.com//page/4/\n",
            "Now Scraping http://quotes.toscrape.com//page/5/\n",
            "Now Scraping http://quotes.toscrape.com//page/6/\n",
            "Now Scraping http://quotes.toscrape.com//page/7/\n",
            "Now Scraping http://quotes.toscrape.com//page/8/\n",
            "Now Scraping http://quotes.toscrape.com//page/9/\n",
            "Now Scraping http://quotes.toscrape.com//page/10/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f7af03a0"
      },
      "source": [
        "## Improve Scraping Robustness and Fix Warning\n",
        "\n",
        "Add error handling for `requests.get` to gracefully handle network issues. The warning related to `_class` has already been fixed in the previous step.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9cf4155a",
        "outputId": "9117bd3b-9029-4dd8-98bd-2cc2693f7423"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from csv import writer\n",
        "from time import sleep\n",
        "from random import choice\n",
        "\n",
        "def scrape_all_quotes():\n",
        "    # list to store scraped data\n",
        "    all_quotes = []\n",
        "\n",
        "    # this part of the url is constant\n",
        "    base_url = \"http://quotes.toscrape.com/\"\n",
        "\n",
        "    # this part of the url will keep changing\n",
        "    url = \"/page/1\"\n",
        "\n",
        "    while url:\n",
        "        try:\n",
        "            # concatenating both urls\n",
        "            # making request with timeout\n",
        "            full_url = f\"{base_url}{url}\"\n",
        "            res = requests.get(full_url, timeout=10)\n",
        "            res.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "            print(f\"Now Scraping {full_url}\")\n",
        "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "            # extracting all elements\n",
        "            quotes = soup.find_all(class_=\"quote\")\n",
        "\n",
        "            for quote in quotes:\n",
        "                all_quotes.append({\n",
        "                    \"text\": quote.find(class_=\"text\").get_text(),\n",
        "                    \"author\": quote.find(class_=\"author\").get_text(),\n",
        "                    \"bio-link\": quote.find(\"a\")[\"href\"]\n",
        "                })\n",
        "            next_btn = soup.find(class_=\"next\")\n",
        "            url = next_btn.find(\"a\")[\"href\"] if next_btn else None\n",
        "            sleep(2)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error scraping {full_url}: {e}\")\n",
        "            url = None # Terminate the loop on error\n",
        "    return all_quotes\n",
        "\n",
        "# Call the function to scrape all quotes\n",
        "all_quotes_data = scrape_all_quotes()\n",
        "\n",
        "# The game-related code is removed as per the instructions."
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Scraping http://quotes.toscrape.com//page/1\n",
            "Now Scraping http://quotes.toscrape.com//page/2/\n",
            "Now Scraping http://quotes.toscrape.com//page/3/\n",
            "Now Scraping http://quotes.toscrape.com//page/4/\n",
            "Now Scraping http://quotes.toscrape.com//page/5/\n",
            "Now Scraping http://quotes.toscrape.com//page/6/\n",
            "Now Scraping http://quotes.toscrape.com//page/7/\n",
            "Now Scraping http://quotes.toscrape.com//page/8/\n",
            "Now Scraping http://quotes.toscrape.com//page/9/\n",
            "Now Scraping http://quotes.toscrape.com//page/10/\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a0f7f22d"
      },
      "source": [
        "## Refactor Game Logic\n",
        "\n",
        "Encapsulate the quote guessing game logic into a function `play_quote_game` that takes the scraped list of quotes as input.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5e6005ff",
        "outputId": "7e6a2686-0f16-4e98-95aa-528a6a5660ff"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from csv import writer\n",
        "from time import sleep\n",
        "from random import choice\n",
        "\n",
        "# This part of the URL is constant and used by both scraping and game logic\n",
        "base_url = \"http://quotes.toscrape.com/\"\n",
        "\n",
        "def scrape_all_quotes():\n",
        "    # list to store scraped data\n",
        "    all_quotes = []\n",
        "\n",
        "    # this part of the url will keep changing\n",
        "    url = \"/page/1\"\n",
        "\n",
        "    while url:\n",
        "        try:\n",
        "            # concatenating both urls\n",
        "            # making request with timeout\n",
        "            full_url = f\"{base_url}{url}\"\n",
        "            res = requests.get(full_url, timeout=10)\n",
        "            res.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "            print(f\"Now Scraping {full_url}\")\n",
        "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "            # extracting all elements\n",
        "            quotes = soup.find_all(class_=\"quote\")\n",
        "\n",
        "            for quote in quotes:\n",
        "                all_quotes.append({\n",
        "                    \"text\": quote.find(class_=\"text\").get_text(),\n",
        "                    \"author\": quote.find(class_=\"author\").get_text(),\n",
        "                    \"bio-link\": quote.find(\"a\")[\"href\"]\n",
        "                })\n",
        "            next_btn = soup.find(class_=\"next\")\n",
        "            url = next_btn.find(\"a\")[\"href\"] if next_btn else None\n",
        "            sleep(2)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error scraping {full_url}: {e}\")\n",
        "            url = None # Terminate the loop on error\n",
        "    return all_quotes\n",
        "\n",
        "def play_quote_game(quotes_data):\n",
        "    quote = choice(quotes_data)\n",
        "    remaining_guesses = 4\n",
        "    print(\"Here's a quote:  \")\n",
        "    print(quote[\"text\"])\n",
        "\n",
        "    guess = ''\n",
        "    while guess.lower() != quote[\"author\"].lower() and remaining_guesses > 0:\n",
        "        guess = input(\n",
        "            f\"Who said this quote? Guesses remaining {remaining_guesses}\")\n",
        "\n",
        "        if guess.lower() == quote[\"author\"].lower():\n",
        "            print(\"CONGRATULATIONS!!! YOU GOT IT RIGHT\")\n",
        "            break\n",
        "        remaining_guesses -= 1\n",
        "\n",
        "        if remaining_guesses == 3:\n",
        "            res = requests.get(f\"{base_url}{quote['bio-link']}\")\n",
        "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "            birth_date = soup.find(class_=\"author-born-date\").get_text()\n",
        "            birth_place = soup.find(class_=\"author-born-location\").get_text()\n",
        "            print(\n",
        "                f\"Here's a hint: The author was born on {birth_date}{birth_place}\")\n",
        "\n",
        "        elif remaining_guesses == 2:\n",
        "            print(\n",
        "                f\"Here's a hint: The author's first name starts with: {quote['author'][0]}\")\n",
        "\n",
        "        elif remaining_guesses == 1:\n",
        "            # Split by space and take the first character of the second word (last name)\n",
        "            author_parts = quote[\"author\"].split(\" \")\n",
        "            if len(author_parts) > 1: # Ensure there is a last name\n",
        "                last_initial = author_parts[1][0]\n",
        "                print(\n",
        "                    f\"Here's a hint: The author's last name starts with: {last_initial}\")\n",
        "            else:\n",
        "                print(\"Here's a hint: The author only has one name, and its first letter is the hint already given.\")\n",
        "\n",
        "        else:\n",
        "            print(\n",
        "                f\"Sorry, you ran out of guesses. The answer was {quote['author']}\")\n",
        "\n",
        "# Call the function to scrape all quotes\n",
        "all_quotes_data = scrape_all_quotes()\n",
        "\n",
        "# Call the function to play the game\n",
        "if all_quotes_data:\n",
        "    play_quote_game(all_quotes_data)\n",
        "else:\n",
        "    print(\"No quotes were scraped. Cannot start the game.\")"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Scraping http://quotes.toscrape.com//page/1\n",
            "Now Scraping http://quotes.toscrape.com//page/2/\n",
            "Now Scraping http://quotes.toscrape.com//page/3/\n",
            "Now Scraping http://quotes.toscrape.com//page/4/\n",
            "Now Scraping http://quotes.toscrape.com//page/5/\n",
            "Now Scraping http://quotes.toscrape.com//page/6/\n",
            "Now Scraping http://quotes.toscrape.com//page/7/\n",
            "Now Scraping http://quotes.toscrape.com//page/8/\n",
            "Now Scraping http://quotes.toscrape.com//page/9/\n",
            "Now Scraping http://quotes.toscrape.com//page/10/\n",
            "Here's a quote:  \n",
            "“I am good, but not an angel. I do sin, but I am not the devil. I am just a small girl in a big world trying to find someone to love.”\n",
            "Who said this quote? Guesses remaining 4anna morgan\n",
            "Here's a hint: The author was born on June 01, 1926in The United States\n",
            "Who said this quote? Guesses remaining 3marilyn monroe\n",
            "CONGRATULATIONS!!! YOU GOT IT RIGHT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8398ff21"
      },
      "source": [
        "## Implement Multiple Game Rounds and Scoring\n",
        "\n",
        "Modify the `play_quote_game` function to allow the user to play multiple rounds, keep track of their score, and display the final score at the end of the game.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1844ba75",
        "outputId": "a620a4d7-63ea-4ca5-9098-8b17ca137231"
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from csv import writer\n",
        "from time import sleep\n",
        "from random import choice\n",
        "\n",
        "# This part of the URL is constant and used by both scraping and game logic\n",
        "base_url = \"http://quotes.toscrape.com/\"\n",
        "\n",
        "def scrape_all_quotes():\n",
        "    # list to store scraped data\n",
        "    all_quotes = []\n",
        "\n",
        "    # this part of the url will keep changing\n",
        "    url = \"/page/1\"\n",
        "\n",
        "    while url:\n",
        "        try:\n",
        "            # concatenating both urls\n",
        "            # making request with timeout\n",
        "            full_url = f\"{base_url}{url}\"\n",
        "            res = requests.get(full_url, timeout=10)\n",
        "            res.raise_for_status() # Raise an HTTPError for bad responses (4xx or 5xx)\n",
        "            print(f\"Now Scraping {full_url}\")\n",
        "            soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "\n",
        "            # extracting all elements\n",
        "            quotes = soup.find_all(class_=\"quote\")\n",
        "\n",
        "            for quote in quotes:\n",
        "                all_quotes.append({\n",
        "                    \"text\": quote.find(class_=\"text\").get_text(),\n",
        "                    \"author\": quote.find(class_=\"author\").get_text(),\n",
        "                    \"bio-link\": quote.find(\"a\")[\"href\"]\n",
        "                })\n",
        "            next_btn = soup.find(class_=\"next\")\n",
        "            url = next_btn.find(\"a\")[\"href\"] if next_btn else None\n",
        "            sleep(2)\n",
        "        except requests.exceptions.RequestException as e:\n",
        "            print(f\"Error scraping {full_url}: {e}\")\n",
        "            url = None # Terminate the loop on error\n",
        "    return all_quotes\n",
        "\n",
        "def play_quote_game(quotes_data):\n",
        "    score = 0\n",
        "    play_again = 'y'\n",
        "\n",
        "    while play_again.lower() == 'y':\n",
        "        quote = choice(quotes_data)\n",
        "        remaining_guesses = 4\n",
        "        print(\"\\nHere's a quote:  \")\n",
        "        print(quote[\"text\"])\n",
        "\n",
        "        guess = ''\n",
        "        while guess.lower() != quote[\"author\"].lower() and remaining_guesses > 0:\n",
        "            guess = input(\n",
        "                f\"Who said this quote? Guesses remaining {remaining_guesses}\")\n",
        "\n",
        "            if guess.lower() == quote[\"author\"].lower():\n",
        "                print(\"CONGRATULATIONS!!! YOU GOT IT RIGHT\")\n",
        "                score += 1\n",
        "                break\n",
        "            remaining_guesses -= 1\n",
        "\n",
        "            if remaining_guesses == 3:\n",
        "                # Fetch author's birth details for the hint\n",
        "                try:\n",
        "                    author_bio_url = f\"{base_url}{quote['bio-link']}\"\n",
        "                    res = requests.get(author_bio_url, timeout=5)\n",
        "                    res.raise_for_status()\n",
        "                    soup = BeautifulSoup(res.text, \"html.parser\")\n",
        "                    birth_date = soup.find(class_=\"author-born-date\").get_text()\n",
        "                    birth_place = soup.find(class_=\"author-born-location\").get_text()\n",
        "                    print(\n",
        "                        f\"Here's a hint: The author was born on {birth_date}{birth_place}\")\n",
        "                except requests.exceptions.RequestException as e:\n",
        "                    print(f\"Could not fetch author bio for hint: {e}\")\n",
        "                    print(\"Here's a hint: I couldn't get more info about the author's birth.\")\n",
        "            elif remaining_guesses == 2:\n",
        "                print(\n",
        "                    f\"Here's a hint: The author's first name starts with: {quote['author'][0]}\")\n",
        "\n",
        "            elif remaining_guesses == 1:\n",
        "                author_parts = quote[\"author\"].split(\" \")\n",
        "                if len(author_parts) > 1: # Ensure there is a last name\n",
        "                    last_initial = author_parts[1][0]\n",
        "                    print(\n",
        "                        f\"Here's a hint: The author's last name starts with: {last_initial}\")\n",
        "                else:\n",
        "                    print(\"Here's a hint: The author only has one name, and its first letter is the hint already given.\")\n",
        "\n",
        "            else:\n",
        "                print(\n",
        "                    f\"Sorry, you ran out of guesses. The answer was {quote['author']}\")\n",
        "\n",
        "        print(f\"Current score: {score}\")\n",
        "        play_again = input(\"Do you want to play another round? (y/n) \")\n",
        "\n",
        "    print(f\"\\nGame Over! Your final score is: {score}\")\n",
        "\n",
        "# Call the function to scrape all quotes\n",
        "all_quotes_data = scrape_all_quotes()\n",
        "\n",
        "# Call the function to play the game\n",
        "if all_quotes_data:\n",
        "    play_quote_game(all_quotes_data)\n",
        "else:\n",
        "    print(\"No quotes were scraped. Cannot start the game.\")"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Now Scraping http://quotes.toscrape.com//page/1\n",
            "Now Scraping http://quotes.toscrape.com//page/2/\n",
            "Now Scraping http://quotes.toscrape.com//page/3/\n",
            "Now Scraping http://quotes.toscrape.com//page/4/\n",
            "Now Scraping http://quotes.toscrape.com//page/5/\n",
            "Now Scraping http://quotes.toscrape.com//page/6/\n",
            "Now Scraping http://quotes.toscrape.com//page/7/\n",
            "Now Scraping http://quotes.toscrape.com//page/8/\n",
            "Now Scraping http://quotes.toscrape.com//page/9/\n",
            "Now Scraping http://quotes.toscrape.com//page/10/\n",
            "\n",
            "Here's a quote:  \n",
            "“Love does not begin and end the way we seem to think it does. Love is a battle, love is a war; love is a growing up.”\n",
            "Who said this quote? Guesses remaining 4keanu reeves\n",
            "Here's a hint: The author was born on August 02, 1924in Harlem, New York, The United States\n",
            "Who said this quote? Guesses remaining 3will smith\n",
            "Here's a hint: The author's first name starts with: J\n",
            "Who said this quote? Guesses remaining 2jackson\n",
            "Here's a hint: The author's last name starts with: B\n",
            "Who said this quote? Guesses remaining 1jackson black\n",
            "Sorry, you ran out of guesses. The answer was James Baldwin\n",
            "Current score: 0\n",
            "Do you want to play another round? (y/n) n\n",
            "\n",
            "Game Over! Your final score is: 0\n"
          ]
        }
      ]
    }
  ]
}